{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten\n",
    "    \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reproduce results\n",
    "seed = 220\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data labels from the csv file\n",
    "data = pd.read_csv('./emergency_class_labels.csv')\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.81410727406319"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class balance\n",
    "data.emergency_or_not.value_counts()\n",
    "data.emergency_or_not.value_counts()[1]/data.emergency_or_not.value_counts()[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, (2352, 224, 224, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load images and store it in a numpy array\n",
    "x = []\n",
    "for img_name in data.image_names:\n",
    "    img = plt.imread('./images/' + img_name)\n",
    "    x.append(img)\n",
    "    \n",
    "x = np.array(x)\n",
    "\n",
    "# create target\n",
    "y = data.emergency_or_not.values\n",
    "\n",
    "x.ndim, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "x_min = x.min()\n",
    "x_max = x.max()\n",
    "x = (x - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and Test set\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(x,y,test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 25)      1900      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 216, 216, 50)      31300     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2332800)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               233280100 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 233,313,401\n",
      "Trainable params: 233,313,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrik\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1646 samples, validate on 706 samples\n",
      "Epoch 1/2\n",
      " 800/1646 [=============>................] - ETA: 5:19 - loss: 0.7134 - accuracy: 0.5863"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=2, validation_data=(X_valid,Y_valid))\n",
    "# model.fit(X_train, Y_train, epochs=10, validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4), padding='valid'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = model.predict_classes(X_valid)[:, 0]\n",
    "prediction_probabilities = model.predict(X_valid)[:, 0]\n",
    "\n",
    "# pull out the original images from the data\n",
    "# which correspond to the validation data\n",
    "_, valid_vehicles, _, valid_y = train_test_split(data.image_names.values, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "# get a random index to plot image randomly\n",
    "index = rng.choice(range(len(valid_vehicles)))\n",
    "\n",
    "# get the corresponding image name and probability\n",
    "img_name = valid_vehicles[index]\n",
    "prob = (prediction_probabilities * 100).astype(int)[index]\n",
    "\n",
    "# read the image\n",
    "img = plt.imread('../datasets/emergency_classification/images/' + img_name)\n",
    "\n",
    "# print probability and actual class\n",
    "print('There is', prob , '% chance that it is an emergency vehicle')\n",
    "print('Whereas actual class is ', valid_y[index])\n",
    "\n",
    "# plot image\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_indices = np.where(predictions != valid_y)[0]\n",
    "\n",
    "index = rng.choice(incorrect_indices)\n",
    "img_name = valid_vehicles[index]\n",
    "\n",
    "\n",
    "prob = (prediction_probabilities * 100).astype(int)[index]\n",
    "\n",
    "img = plt.imread('../datasets/emergency_classification/images/' + img_name)\n",
    "\n",
    "print(prob , '% sure that it is emergency')\n",
    "print('Whereas actual class is ', valid_y[index])\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change activation function of hidden layer\n",
    "# increase hidden neurons\n",
    "# increase hidden layers\n",
    "# increase number of epochs\n",
    "# change optimizer\n",
    "\n",
    "# increase number of convolutional layers\n",
    "# increase number of pooling layers\n",
    "# increase number of convolutional filters\n",
    "# change size of conv\n",
    "# change size of pooling\n",
    "# change padding technique\n",
    "# change stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase number of convolutional and pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(100, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4), padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase number of convolutional filters\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(125, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(Conv2D(150, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(200, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPool2D(pool_size=(4, 4), padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change filter size for convolutional layer and pooling size for pooling layer\n",
    "\n",
    "from keras.layers import GlobalMaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(125, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(Conv2D(150, (5, 5), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(MaxPool2D(pool_size=(8, 8), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(200, (3, 3), activation='relu', strides=(1, 1), padding='valid'))\n",
    "model.add(Conv2D(225, (3, 3), activation='relu', strides=(1, 1), padding='valid'))\n",
    "\n",
    "model.add(GlobalMaxPool2D())\n",
    "\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change padding technique\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(125, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(Conv2D(150, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(8, 8), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(200, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(Conv2D(225, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
    "\n",
    "model.add(GlobalMaxPool2D())\n",
    "\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change stride\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(125, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(Conv2D(150, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(8, 8), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(200, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(Conv2D(225, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "\n",
    "model.add(GlobalMaxPool2D())\n",
    "\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=15,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG equivalent\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters = 512, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 1024, activation ='sigmoid'))\n",
    "model.add(Dense(units=1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=200,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
